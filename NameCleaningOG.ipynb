{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cleaning the Names of the Data</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the library to read the excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the excel into the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Age</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>Result</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>m/s</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Year D.O.B.</th>\n",
       "      <th>Info, if any</th>\n",
       "      <th>Date of Birth (PDPA)</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-14 00:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Men High Jump</td>\n",
       "      <td>KAM, KAMPTON</td>\n",
       "      <td>22</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>2.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>International - Penn 10-Team Select</td>\n",
       "      <td>2000</td>\n",
       "      <td>Sanctioned,1pos</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-04 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Men Long Jump</td>\n",
       "      <td>TOH, WEI YU</td>\n",
       "      <td>-</td>\n",
       "      <td>NANYANG TECHNOLOGICAL UNI</td>\n",
       "      <td>6.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Local - IVP</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-04 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Men Long Jump</td>\n",
       "      <td>MUHAMAD NURSHAHILMI, BIN NORADEE</td>\n",
       "      <td>-</td>\n",
       "      <td>TEMASEK POLYTECHNIC</td>\n",
       "      <td>6.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Local - IVP</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-04 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Men Long Jump</td>\n",
       "      <td>SEBASTIAN, KIRAN</td>\n",
       "      <td>-</td>\n",
       "      <td>REPUBLIC POLYTECHNIC</td>\n",
       "      <td>6.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Local - IVP</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-04 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Men Long Jump</td>\n",
       "      <td>NAING, KYAW LINN</td>\n",
       "      <td>-</td>\n",
       "      <td>SINGAPORE MANAGEMENT UNI</td>\n",
       "      <td>6.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Local - IVP</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122793</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-17 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Men 100 Meter Dash</td>\n",
       "      <td>Azhari Muhd Yusof</td>\n",
       "      <td>17</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>11.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>International - Asian Junior</td>\n",
       "      <td>1989</td>\n",
       "      <td>Semis, 7/8pos</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122794</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-17 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Women Discus Throw (1kg)</td>\n",
       "      <td>Wan, Lay Chi</td>\n",
       "      <td>18</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>44.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>International - Asian Junior</td>\n",
       "      <td>1988</td>\n",
       "      <td>Final, 6/14pos</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122795</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-17 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Women 100 Meter Dash</td>\n",
       "      <td>Ann Siao Mei</td>\n",
       "      <td>19</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>12.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3</td>\n",
       "      <td>International - Asian Junior</td>\n",
       "      <td>1987</td>\n",
       "      <td>R1, 5/7pos</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122796</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-17 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Women 100 Meter Dash</td>\n",
       "      <td>Choo Sze-Min, Amanda</td>\n",
       "      <td>19</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>12.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>International - Asian Junior</td>\n",
       "      <td>1987</td>\n",
       "      <td>R1, 4/6pos q</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122797</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-07-17 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Women 100 Meter Dash</td>\n",
       "      <td>Choo Sze-Min, Amanda</td>\n",
       "      <td>19</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>12.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>International - Asian Junior</td>\n",
       "      <td>1987</td>\n",
       "      <td>Final, 8/8pos</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122796 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                 Date  Day  Month    Year  \\\n",
       "0              NaN  2023-01-14 00:00:00   14    1.0  2023.0   \n",
       "1              NaN  2023-01-04 00:00:00    4    1.0  2023.0   \n",
       "2              NaN  2023-01-04 00:00:00    4    1.0  2023.0   \n",
       "3              NaN  2023-01-04 00:00:00    4    1.0  2023.0   \n",
       "4              NaN  2023-01-04 00:00:00    4    1.0  2023.0   \n",
       "...            ...                  ...  ...    ...     ...   \n",
       "122793         NaN  2006-07-17 00:00:00   17    7.0  2006.0   \n",
       "122794         NaN  2006-07-17 00:00:00   17    7.0  2006.0   \n",
       "122795         NaN  2006-07-17 00:00:00   17    7.0  2006.0   \n",
       "122796         NaN  2006-07-17 00:00:00   17    7.0  2006.0   \n",
       "122797         NaN  2006-07-17 00:00:00   17    7.0  2006.0   \n",
       "\n",
       "                           Event                              NAME Age  \\\n",
       "0                  Men High Jump                      KAM, KAMPTON  22   \n",
       "1                  Men Long Jump                       TOH, WEI YU   -   \n",
       "2                  Men Long Jump  MUHAMAD NURSHAHILMI, BIN NORADEE   -   \n",
       "3                  Men Long Jump                  SEBASTIAN, KIRAN   -   \n",
       "4                  Men Long Jump                  NAING, KYAW LINN   -   \n",
       "...                          ...                               ...  ..   \n",
       "122793        Men 100 Meter Dash                 Azhari Muhd Yusof  17   \n",
       "122794  Women Discus Throw (1kg)                      Wan, Lay Chi  18   \n",
       "122795      Women 100 Meter Dash                      Ann Siao Mei  19   \n",
       "122796      Women 100 Meter Dash              Choo Sze-Min, Amanda  19   \n",
       "122797      Women 100 Meter Dash              Choo Sze-Min, Amanda  19   \n",
       "\n",
       "                             TEAM Result  Unnamed: 10  m/s  \\\n",
       "0                      INDIVIDUAL   2.06          NaN    -   \n",
       "1       NANYANG TECHNOLOGICAL UNI   6.64          NaN  0.2   \n",
       "2             TEMASEK POLYTECHNIC   6.28          NaN  0.1   \n",
       "3            REPUBLIC POLYTECHNIC   6.27          NaN  1.7   \n",
       "4        SINGAPORE MANAGEMENT UNI   6.26          NaN  1.2   \n",
       "...                           ...    ...          ...  ...   \n",
       "122793                  Singapore  11.12          NaN -0.4   \n",
       "122794                  Singapore  44.85          NaN    -   \n",
       "122795                  Singapore  12.93          NaN   -3   \n",
       "122796                  Singapore  12.39          NaN  0.2   \n",
       "122797                  Singapore  12.39          NaN -0.8   \n",
       "\n",
       "                                Competition Year D.O.B.     Info, if any  \\\n",
       "0       International - Penn 10-Team Select        2000  Sanctioned,1pos   \n",
       "1                               Local - IVP           -                -   \n",
       "2                               Local - IVP           -                -   \n",
       "3                               Local - IVP           -                -   \n",
       "4                               Local - IVP           -                -   \n",
       "...                                     ...         ...              ...   \n",
       "122793         International - Asian Junior        1989    Semis, 7/8pos   \n",
       "122794         International - Asian Junior        1988   Final, 6/14pos   \n",
       "122795         International - Asian Junior        1987       R1, 5/7pos   \n",
       "122796         International - Asian Junior        1987     R1, 4/6pos q   \n",
       "122797         International - Asian Junior        1987    Final, 8/8pos   \n",
       "\n",
       "       Date of Birth (PDPA) Unnamed: 16  \n",
       "0                         -         NaN  \n",
       "1                         -         NaN  \n",
       "2                         -         NaN  \n",
       "3                         -         NaN  \n",
       "4                         -         NaN  \n",
       "...                     ...         ...  \n",
       "122793                    -         NaN  \n",
       "122794                    -         NaN  \n",
       "122795                    -         NaN  \n",
       "122796                    -         NaN  \n",
       "122797                    -         NaN  \n",
       "\n",
       "[122796 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_excel('RawData/Ranking.xlsx', sheet_name='Consolidated2')\n",
    "df = df[df['NAME'].notna()]\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split all names into first and last name, remove the relays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffnln=df.copy()\n",
    "dffnln=dffnln.loc[~(dffnln['Event'].isin(['Women 4x400 Meter Relay', ' Men 4x400 Meter Relay', 'Men 4x400 Meter Relay', 'Mixed 4x400 Meter Relay', 'Women 4x100 Meter Relay', 'Men 4x100 Meter Relay', 'Mixed 4x100 Meter Relay']))]\n",
    "dffnln.Event.unique()\n",
    "\n",
    "dffnln['FirstName'] = dffnln['NAME'].str.split(',').str[0]\n",
    "dffnln['LastName'] = dffnln['NAME'].str.split(',').str[-1]\n",
    "\n",
    "\n",
    "\n",
    "# writer = pd.ExcelWriter('Checkpoints.xlsx', engine = 'openpyxl')\n",
    "# dffnln.to_excel(writer, sheet_name = 'FirstNameLastName')\n",
    "# writer.close()\n",
    "\n",
    "# dffnln.to_csv('Checkpoint1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning to check the similarities between names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5163977794943222"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    # print vec1, vec2\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "    return Counter(WORD.findall(text))\n",
    "\n",
    "def get_similarity(a, b):\n",
    "    a = text_to_vector(a.strip().lower())\n",
    "    b = text_to_vector(b.strip().lower())\n",
    "\n",
    "    return get_cosine(a, b)\n",
    "\n",
    "get_similarity('TAN ELIZABETH-A', 'TAN ELIZABETH ANN SHEE RU') # returns 0.9258200997725514"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all similar names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(map(lambda v: v in ('BIN ZAINAL MUHAMMAD FAZREY'.lower()).split(' '), ['mohamad', 'muhammad', 'mohammad', 'muhammad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToCheck={}\n",
    "# dfname=dffnln.copy()\n",
    "# # dfname=dfname.drop_duplicates(subset=['NAME'])\n",
    "# # dfname.to_csv('dfname.csv')\n",
    "\n",
    "# counter=0\n",
    "\n",
    "# for firstname, lastname in zip(dfname['FirstName'], dfname['LastName']):\n",
    "#     counter+=1\n",
    "#     for keys in ToCheck.keys():\n",
    "#         i, j=keys.split('/')[0], keys.split('/')[-1]\n",
    "#         score1=get_similarity(firstname,i)\n",
    "#         score2=get_similarity(lastname, j)\n",
    "#         if any(map(lambda v: v in (firstname.lower()+lastname.lower()).split(' '), ['mohamad', 'muhammad', 'mohammad', 'muhammad'])): \n",
    "#             # print(firstname, lastname)\n",
    "#             if score1>0.7 and score2>0.7:\n",
    "#                 ToCheck[keys]+=[f'{firstname}/{lastname} ({round(score1, 2), round(score2, 2)})']\n",
    "#                 # print(f'{firstname} // {i}')\n",
    "#                 break\n",
    "#             else:\n",
    "#                 scoreboth=get_similarity(firstname+lastname,keys)\n",
    "#                 if scoreboth>0.7:\n",
    "#                     ToCheck[keys]+=[f'{firstname}/{lastname} ({round(scoreboth, 2)})']\n",
    "#                     break\n",
    "#         else:\n",
    "#             if score1>0.5 and score2>0.5:\n",
    "#                 ToCheck[keys]+=[f'{firstname}/{lastname} ({round(score1, 2), round(score2, 2)})']\n",
    "#                 # print(f'{firstname} // {i}')\n",
    "#                 break\n",
    "#             else:\n",
    "#                 scoreboth=get_similarity(firstname+lastname,keys)\n",
    "#                 if scoreboth>0.5:\n",
    "#                     ToCheck[keys]+=[f'{firstname}/{lastname} ({round(scoreboth, 2)})']\n",
    "#                     break\n",
    "#     else:\n",
    "#         ToCheck[(firstname+'/'+lastname).upper()]=[]\n",
    "\n",
    "#     if counter%500==0:\n",
    "#         print(f'{counter} out of {len(dfname)} completed.')\n",
    "\n",
    "# pd.DataFrame(pd.Series(ToCheck)).to_csv('Checkpoint6.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UniqueNames=[''] ##Can consider dropping the mohammad when comparing or dropping punctuation\n",
    "# counter=0\n",
    "# checkdf=dffnln.copy()\n",
    "# checkdf=checkdf.drop_duplicates(subset=['NAME'])\n",
    "# checkdf.to_csv('checkpoint3.csv')\n",
    "\n",
    "\n",
    "# for name, team, age in zip(checkdf['NAME'], checkdf['TEAM'], checkdf['Age']):\n",
    "#     # print(i)\n",
    "#     counter+=1\n",
    "#     for j in UniqueNames:\n",
    "#         score=get_similarity(name,j)\n",
    "#         if 'MOHAMMAD' in name:\n",
    "#             if score > 0.65: #Check if the names is already in the UniqueNames, if similarity score >60% means same name\n",
    "#                 if len(name)>=len(j): #Take the longer name for the Unique Names\n",
    "#                     # with open(\"output.txt\", \"a\") as f:\n",
    "#                     #     print(f\"Replacing {j} ({len(j)}) with {i} ({len(i)}). {counter}\", file=f)\n",
    "#                     # UniqueNameReplace=bool(input(f\"Replace {name.upper()} with {j.upper()}.?\"))\n",
    "#                     # if UniqueNameReplace:\n",
    "#                     UniqueNames[UniqueNames.index(j)]=name\n",
    "#                 break\n",
    "#         else:\n",
    "#             if score > 0.70: #Check if the names is already in the UniqueNames, if similarity score >60% means same name\n",
    "#                 if len(name)>=len(j): #Take the longer name for the Unique Names\n",
    "#                     # with open(\"output.txt\", \"a\") as f:\n",
    "#                     #     print(f\"Replacing {j} ({len(j)}) with {i} ({len(i)}). {counter}\", file=f)\n",
    "#                     # UniqueNameReplace=bool(input(f\"Replace {name.upper()} with {j.upper()}.?\"))\n",
    "#                     # if UniqueNameReplace:\n",
    "#                     UniqueNames[UniqueNames.index(j)]=name\n",
    "#                 break\n",
    "            \n",
    "#     else:\n",
    "#         # with open(\"output.txt\", \"a\") as f:\n",
    "#         #     print(f\"Adding {i} into Unique Names.\", file=f)\n",
    "\n",
    "#         UniqueNames.append(name)\n",
    "    \n",
    "#     if counter%500==0:\n",
    "#         print(f'{counter} out of {len(checkdf)} done.')\n",
    "\n",
    "# print(len(UniqueNames))\n",
    "# print(ToCheck)\n",
    "\n",
    "# Checking=pd.DataFrame(UniqueNames)\n",
    "# Checking.to_csv('Checkpoint5.csv')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UniqueNames={'Name': 'Team'}\n",
    "# counter=0\n",
    "# checkdf=dffnln.copy()\n",
    "# checkdf=checkdf.drop_duplicates(subset=['NAME'])\n",
    "# checkdf.to_csv('checkpoint3.csv')\n",
    "# for name, team, age in zip(checkdf['NAME'], checkdf['TEAM'], checkdf['Age']):\n",
    "#     # print(i)\n",
    "#     counter+=1\n",
    "#     for j in UniqueNames:\n",
    "#         score=get_similarity(name,j)\n",
    "#         if 'MOHAMMAD' in name:\n",
    "#             if score > 0.65 and team==UniqueNames[j]: #Check if the names is already in the UniqueNames, if similarity score >60% means same name\n",
    "#                 if len(name)>=len(j): #Take the longer name for the Unique Names\n",
    "#                     # with open(\"output.txt\", \"a\") as f:\n",
    "#                     #     print(f\"Replacing {j} ({len(j)}) with {i} ({len(i)}). {counter}\", file=f)\n",
    "#                     UniqueNameReplace=bool(input(f\"Replace {name.upper()} with {j.upper()}.?\"))\n",
    "#                     if UniqueNameReplace:\n",
    "#                         UniqueNames[j]=name.upper()\n",
    "\n",
    "#                 break\n",
    "#         else:\n",
    "#             if score > 0.70: #Check if the names is already in the UniqueNames, if similarity score >60% means same name\n",
    "#                 if len(name)>=len(j) and team==UniqueNames[j]: #Take the longer name for the Unique Names\n",
    "#                     # with open(\"output.txt\", \"a\") as f:\n",
    "#                     #     print(f\"Replacing {j} ({len(j)}) with {i} ({len(i)}). {counter}\", file=f)\n",
    "#                     UniqueNameReplace=bool(input(f\"Replace {name.upper()} with {j.upper()}.?\"))\n",
    "#                     if UniqueNameReplace:\n",
    "#                         UniqueNames[j]=name.upper()\n",
    "\n",
    "#                 break\n",
    "            \n",
    "#     else:\n",
    "#         # with open(\"output.txt\", \"a\") as f:\n",
    "#         #     print(f\"Adding {i} into Unique Names.\", file=f)\n",
    "\n",
    "#         UniqueNames[name]=team\n",
    "    \n",
    "#     if counter%500==0:\n",
    "#         print(f'{counter} out of {len(checkdf)} done.')\n",
    "\n",
    "# print(len(UniqueNames))\n",
    "\n",
    "# Checking=pd.DataFrame({'Name':[i for i in UniqueNames.keys()], 'Team': [j for j in UniqueNames.values()]})\n",
    "# Checking.to_csv('Checkpoint5.csv')\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfUniqueName=dffnln.copy()\n",
    "# EditedNames=[]\n",
    "# counter=0\n",
    "\n",
    "# for i in dfUniqueName['NAME']:\n",
    "#     counter+=1\n",
    "#     # print(i)\n",
    "#     for j in UniqueNames:\n",
    "#         score=get_similarity(i,j)\n",
    "#         if 'MOHAMMAD' in i:\n",
    "#             if score > 0.65: #Check if the names is already in the UniqueNames, if similarity score >60% means same name\n",
    "#                 EditedNames.append(j)\n",
    "#                 break\n",
    "#         else:\n",
    "#             if score > 0.55:\n",
    "#                 EditedNames.append(j)\n",
    "#                 break\n",
    "#     else:\n",
    "#         EditedNames.append('No Match')\n",
    "    \n",
    "#     # print(f'i is {i}, j is {j}')\n",
    "\n",
    "#     if counter%500==0:\n",
    "#         print(f'{counter} out of {len(dfUniqueName)} done.')\n",
    "\n",
    "# dfUniqueName['Edited Names']=EditedNames\n",
    "\n",
    "# dfUniqueName.to_csv('Checkpoint4.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign UniqueID to all names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UniqueNames={}\n",
    "# # counter=0\n",
    "# # for key,value in dffnln['NAME'].items():\n",
    "# #     if value not in UniqueNames:\n",
    "# #         UniqueNames[value]=counter\n",
    "# #         counter+=1\n",
    "\n",
    "# dffnln['UniqueID']=(dffnln['FirstName'].str[:2]+dffnln['LastName'].str[:2]+dffnln['Year D.O.B.'].astype(str)).str.replace(' ', '')    \n",
    "# # writer = pd.ExcelWriter('Checkpoints.xlsx', engine = 'openpyxl')\n",
    "# # dffnln.to_excel(writer, sheet_name = 'UniqueID')\n",
    "# # writer.close()\n",
    "\n",
    "# dffnln.to_csv('Checkpoint2.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UniqueNames=pd.read_csv('UniqueNames.csv')\n",
    "# Changer=[]\n",
    "\n",
    "# UniqueNames.columns=['Name', 'Edit']\n",
    "# # check=UniqueNames['Edit'].tolist()\n",
    "# # Changer=[]\n",
    "# for names in UniqueNames['Edit']:\n",
    "#     # print(names)\n",
    "#     newname=re.sub( \"\\s*\\(.*?\\)\\s*\",\" \",names)\n",
    "#     newname=newname.replace('[]','')\n",
    "#     newname=newname.replace('[','')\n",
    "#     newname=newname.replace(']', '')\n",
    "#     newname=newname.replace('(', '')\n",
    "#     newname=newname.replace(')', '')\n",
    "#     newname=newname.replace(\"'\", '')\n",
    "#     newname=newname.replace(\"'\", '')\n",
    "#     newname=newname.replace('/', '')\n",
    "#     Changer.append(newname)\n",
    "#     # print(newname)\n",
    "#     # Changer.append(re.sub( \"\\s*\\(.*?\\)\\s*\",\" \",names))\n",
    "#     # Changer.append(name.replace('[]', ''))\n",
    "\n",
    "# UniqueNames['NameFix']=UniqueNames['Name'].replace(['/', \"'\", '(', ')'],'')\n",
    "# UniqueNames['ChangetoThese']=Changer\n",
    "# UniqueNames.to_csv('UniqueNamesEdited.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namedb=pd.read_csv('UniqueNamesRev13.csv')\n",
    "# Namedb=Namedb.fillna('EMPTY')\n",
    "# # newdf=pd.read_csv('dfname.csv')\n",
    "# newdf=dffnln.copy()\n",
    "# toreplace=[]\n",
    "# formetocheck={}\n",
    "# counter=0\n",
    "\n",
    "# # for k in Namedb.keys():\n",
    "# #     print(Namedb[k])\n",
    "\n",
    "# # print(True in Namedb['TAN ELIZABETH ANN SHEE RU'].str.contains('TAN ELIZABETH ANN SHEE RU' ))\n",
    "# # for i in Namedb.keys():\n",
    "# #     print('KAM KAMPTON' == i)\n",
    "# # print('SO GOTHANDARAMAN BHUVANESH' in Namedb.items())\n",
    "\n",
    "# # for k, v in Namedb.items():\n",
    "# #     if 'SO GOTHANDARAMAN/ BHUVANESH' in v: \n",
    "# #         print('yes')\n",
    "# #         break\n",
    "\n",
    "# # print('KAM KAMPTON' in Namedb.keys())\n",
    "\n",
    "# newdf['CheckNames']=newdf['Name'].replace(',', '', regex=True)\n",
    "# newdf['CheckNames']=newdf['Name'].replace(\"'\", '', regex=True)\n",
    "# newdf['CheckNames']=newdf['CheckNames'].str.upper()\n",
    "# newdf['CheckNames']=newdf['CheckNames'].str.strip()\n",
    "# # print(newdf['CheckNames'])\n",
    "# for names in newdf['CheckNames']:\n",
    "#     names=names.replace(',', '')\n",
    "#     names=names.strip()\n",
    "#     for k in Namedb.keys():\n",
    "#         try:\n",
    "#             if names.upper()==k:\n",
    "#                 toreplace.append(k)\n",
    "#                 formetocheck[names]=k\n",
    "#                 break\n",
    "#             elif (Namedb[k].str.match(names.upper()).any()): #please remove all the unnamed rows if get the .str accessor error\n",
    "#                 toreplace.append(k)\n",
    "#                 formetocheck[names]=k\n",
    "#                 break\n",
    "#         except:\n",
    "#             toreplace.append('Error')\n",
    "#             formetocheck[names]='Error'\n",
    "#             break\n",
    "#     else:\n",
    "#         toreplace.append('No Match')\n",
    "#         formetocheck[names]='No Match'\n",
    "#         # print(names)\n",
    "\n",
    "#     counter+=1\n",
    "#     if counter%500==0:\n",
    "#         print(f'{counter} out of {len(newdf[\"Name\"])} done.')\n",
    "\n",
    "# newdf['NAME EDITED']=toreplace\n",
    "# newdf.to_csv('2014.csv')\n",
    " \n",
    "# #Just run this and wait 30 mins to see if it works\n",
    "\n",
    "# # Namedb.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(toreplace).to_csv('ToReplace.csv')\n",
    "# pd.DataFrame(formetocheck).to_csv('ForMeToCheck.csv')\n",
    "\n",
    "# newdf.to_csv('2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115155\n",
      "0 out of 115155 done.\n",
      "500 out of 115155 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_2940\\2783775925.py:22: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if UniqueNames['Actual Names'].str.contains(names).any():\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_2940\\2783775925.py:25: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  elif UniqueNames['Var1'].str.contains(names).any():\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_2940\\2783775925.py:29: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  elif UniqueNames['Var2'].str.contains(names).any():\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_2940\\2783775925.py:33: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  elif UniqueNames['Var3'].str.contains(names).any():\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_2940\\2783775925.py:37: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  elif UniqueNames['Var4'].str.contains(names).any():\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_2940\\2783775925.py:39: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  row_num=[i for i, x in enumerate(UniqueNames['Var4'].str.contains(names)) if x]\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_2940\\2783775925.py:35: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  row_num=[i for i, x in enumerate(UniqueNames['Var3'].str.contains(names)) if x]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 115155 done.\n"
     ]
    }
   ],
   "source": [
    "UniqueNames=pd.read_excel('NameVariationDict/UniqueNamesRev24.xlsx')\n",
    "UniqueNames=UniqueNames.fillna('NIL')\n",
    "UniqueNames.reset_index()\n",
    "newdf=dffnln.copy() #Copy the dataframe to prevent any alteration to original file\n",
    "counter=0 #To see the progress of the code\n",
    "toreplace=[]\n",
    "\n",
    "#Create a column called CheckNames to read all the names without the commas. Make all captial also\n",
    "newdf['CheckNames']=newdf['NAME'].replace(',', '', regex=True)\n",
    "newdf['CheckNames']=newdf['CheckNames'].str.upper()\n",
    "newdf['CheckNames']=newdf['CheckNames'].str.strip()\n",
    "print(len(newdf))\n",
    "\n",
    "\n",
    "\n",
    "for names in newdf['CheckNames']:\n",
    "    if counter%500==0:\n",
    "        print(f'{counter} out of {len(newdf[\"CheckNames\"])} done.')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        if UniqueNames['Actual Names'].str.contains(names).any():\n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Actual Names'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var1'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var1'] == names].index\n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var1'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var2'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var2'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var2'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var3'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var3'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var3'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var4'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var4'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var4'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var5'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var5'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var5'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var6'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var6'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var6'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var7'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var7'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var7'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var8'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var8'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var8'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var9'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var9'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var9'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var10'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var10'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var10'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var11'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var11'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var11'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var12'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var12'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var12'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var13'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var13'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var13'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var14'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var14'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var14'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var15'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var15'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var16'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var16'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var17'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var17'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var18'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var18'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var19'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var19'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var20'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var20'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var21'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var21'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var22'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var22'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var23'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var23'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var24'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var24'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var25'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var25'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var26'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var26'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var27'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var27'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var28'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var28'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var29'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var29'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var30'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var30'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var31'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var31'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var32'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var32'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var33'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var33'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var34'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var34'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var35'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var35'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var36'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var36'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        elif UniqueNames['Var37'].str.contains(names).any():\n",
    "            # row_num = UniqueNames[UniqueNames['Var15'] == names].index \n",
    "            row_num=[i for i, x in enumerate(UniqueNames['Var37'].str.contains(names)) if x]\n",
    "            toreplace.append(UniqueNames['Actual Names'][row_num[0]])\n",
    "        else:\n",
    "            toreplace.append('NoMatch')\n",
    "        counter+=1\n",
    "    except:\n",
    "        toreplace.append('Error')\n",
    "        counter+=1\n",
    "\n",
    "#Replace all the original names to the correct names\n",
    "newdf['NAME EDITED']=toreplace\n",
    "\n",
    "#Remember to rename the file everytime it is produced\n",
    "newdf.to_excel('RawData/CONSOLIDATED.xlsx')\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniqueNames['Actual Names'].str.contains('TAN ELIZABETH-ANN').any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
